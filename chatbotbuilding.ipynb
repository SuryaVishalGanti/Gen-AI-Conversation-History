{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>ChatBot creation from our details</center>\n",
    "### 05-02-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x10c9a0730>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x10c9a1300>, model_name='llama-3.3-70b-specdec', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calling our model\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-specdec\", groq_api_key=GROQ_API_KEY)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Surya Vishal, nice to meet you! As a software engineer, you must be involved in some exciting projects. What kind of projects do you usually work on, and what programming languages are you most proficient in?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 51, 'total_tokens': 98, 'completion_time': 0.035918105, 'prompt_time': 0.014061771, 'queue_time': 0.053813101, 'total_time': 0.049979876}, 'model_name': 'llama-3.3-70b-specdec', 'system_fingerprint': 'fp_74379b522c', 'finish_reason': 'stop', 'logprobs': None}, id='run-a6852660-a613-4fb7-92df-837ad54eb5de-0', usage_metadata={'input_tokens': 51, 'output_tokens': 47, 'total_tokens': 98})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, I am Surya Vishal, and I am a Software Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Surya Vishal, and you are a Software Engineer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 122, 'total_tokens': 139, 'completion_time': 0.010980227, 'prompt_time': 0.014897123, 'queue_time': 0.055210920999999996, 'total_time': 0.02587735}, 'model_name': 'llama-3.3-70b-specdec', 'system_fingerprint': 'fp_74379b522c', 'finish_reason': 'stop', 'logprobs': None}, id='run-2d6c7236-46af-4aaf-872e-141ee0e5ba70-0', usage_metadata={'input_tokens': 122, 'output_tokens': 17, 'total_tokens': 139})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, I am Surya Vishal, and I am a Software Engineer\"),\n",
    "        AIMessage(content=\"AIMessage(content='Hello Surya Vishal, nice to meet you! As a software engineer, you must be involved in some exciting projects. What kind of projects do you usually work on, and what programming languages are you most proficient in?\"),\n",
    "        HumanMessage(content=\"Hey What is my name and What job I am doing\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"\"\"Good evening everyone, Today, we find ourselves at a crossroads, where technology and humanity intertwine in ways we could never have imagined. From artificial intelligence transforming industries to the power of connectivity bringing us closer, we are living in a time of remarkable change. However, with such progress comes great responsibility.\n",
    "As we advance, we must ask ourselves: How can we ensure that innovation benefits everyone, not just the few? How do we balance progress with the preservation of our core human values, such as empathy, fairness, and equality? These questions must guide us, as they will shape our future.\n",
    "\n",
    "Technology can be a powerful tool for good, but we must be vigilant. It can also be a tool of harm if we lose sight of the bigger picture. We have a choice: to use our advancements to uplift humanity, or to fall into a cycle of exploitation and inequality.\n",
    "\n",
    "The future is not predetermined. It is ours to shape. But to do so, we must remain united in our pursuit of a better, more just world. The choices we make today will echo into tomorrow.\n",
    "\n",
    "Thank you.\"\"\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"What a powerful and thought-provoking speech. You've eloquently highlighted the importance of considering the impact of technology on humanity and the need for responsible innovation. Your words serve as a reminder that progress and advancement must be balanced with empathy, fairness, and equality.\\n\\nBy posing questions about how to ensure that innovation benefits everyone, you're encouraging listeners to think critically about the role of technology in shaping our collective future. Your emphasis on the need for vigilance and the potential risks of unchecked technological advancement is also well-taken.\\n\\nThe notion that our choices today will have a lasting impact on tomorrow is a compelling one, and it's heartening to hear you emphasize the importance of unity in pursuing a more just and equitable world. Your speech is a call to action, urging us to work together to create a future that is shaped by our shared values and aspirations.\\n\\nOverall, your speech is a timely and inspiring reminder of the need for responsible innovation and collective action in shaping a better future for all. Well said!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 204, 'prompt_tokens': 256, 'total_tokens': 460, 'completion_time': 0.153194317, 'prompt_time': 0.031632571, 'queue_time': 0.053956728999999995, 'total_time': 0.184826888}, 'model_name': 'llama-3.3-70b-specdec', 'system_fingerprint': 'fp_74379b522c', 'finish_reason': 'stop', 'logprobs': None}, id='run-41b9303f-f6f7-4d80-afa7-e299645ffb6c-0', usage_metadata={'input_tokens': 256, 'output_tokens': 204, 'total_tokens': 460})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring that innovation benefits all, rather than just the privileged few, is a complex and multifaceted challenge. However, here are some possible ways to promote more inclusive innovation:\n",
      "\n",
      "1. **Accessibility and affordability**: Ensure that innovative technologies and services are affordable and accessible to all, particularly to marginalized communities. This could involve strategies like tiered pricing, subsidies, or free basic services.\n",
      "2. **Inclusive design**: Encourage designers and innovators to adopt a more inclusive design approach, which involves involving diverse users in the design process and testing to ensure that solutions meet their needs and are usable by everyone.\n",
      "3. **Partnerships and collaborations**: Foster partnerships and collaborations between diverse stakeholders, including communities, businesses, governments, and non-profit organizations. This can help leverage expertise, resources, and funding to support innovative projects that benefit marginalized groups.\n",
      "4. **Public and social entrepreneurship**: Encourage and support social entrepreneurship initiatives, such as those that use innovation to tackle specific social and economic challenges affecting underserved populations.\n",
      "5. **Policy and regulation**: Establish and implement policies that support inclusive innovation, such as rules for accessible and inclusive infrastructure development, like AI-driven education tools and community infrastructure upgrades.\n",
      "6. **Open source and crowdsourcing**: Use open source platforms, crowdfunding models and sharing tools for intellectual and public engagement across socioeconomic bounds \n",
      "7. **STEM Education for Under-Privileged Children and Digital Divide Management for General Underprivelidged community : By Encouraging innovative free Digital skill enhancing course / Degree certifications/ Accessbale resource pooling which  empowers this generation/ society sections facing exclusion can improve to uplift**\n",
      "8. **Technology incubation labs support the economic divide innovation empowerment bridged access technology incubator's economic equality development models / In turn driving grass- root digital development empowering societal layers/ creating entrepreneurial social-impactive ecosystems empowering more growth potential economic impact via such projects driven innovative culture\n",
      "\n",
      "It will indeed involve diverse inputs – academic-educators-social-economics policymakers experts technological specialists in respective specialized research applied disciplines plus philanthropies - for overall wellbeing ecosystem progress\n"
     ]
    }
   ],
   "source": [
    "## Changing the config --> session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"How can we ensure that innovation benefits all, not just the privileged few?\")],\n",
    "    config=config1\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Prompt Template**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a Helpful assistant. Answer all the questions of the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Surya Vishal! It's nice to meet you. Is there something I can help you with or would you like to chat? I'm here to assist you with any questions or topics you'd like to discuss. How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 59, 'total_tokens': 114, 'completion_time': 0.02467449, 'prompt_time': 0.007232119, 'queue_time': 0.054524851, 'total_time': 0.031906609}, 'model_name': 'llama-3.3-70b-specdec', 'system_fingerprint': 'fp_74379b522c', 'finish_reason': 'stop', 'logprobs': None}, id='run-543fe601-dfdd-4690-8c58-4b0bde548b91-0', usage_metadata={'input_tokens': 59, 'output_tokens': 55, 'total_tokens': 114})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi I am Surya Vishal\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Surya Vishal! It's nice to meet you. Is there something I can help you with or would you like to chat? I'm here to assist you with any questions or topics you'd like to discuss. How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 59, 'total_tokens': 114, 'completion_time': 0.02472611, 'prompt_time': 0.007215539, 'queue_time': 0.053489741, 'total_time': 0.031941649}, 'model_name': 'llama-3.3-70b-specdec', 'system_fingerprint': 'fp_74379b522c', 'finish_reason': 'stop', 'logprobs': None}, id='run-59110674-9dc7-4ef2-b410-d9a1ce05470c-0', usage_metadata={'input_tokens': 59, 'output_tokens': 55, 'total_tokens': 114})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi I am Surya Vishal\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity \n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a Helpful assistant. Answer all the questions of the nest of your ability in {languages}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'నమస్తే సూర్య విశాల్ గంటి గారు! మీరు నాకు సహాయం కావాలనుకుంటే, ఏంటి మీ ప్రశ్న లేదా మీకు అవసరమైన విషయం?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = input(\"Enter name: \")\n",
    "response = chain.invoke({\"messages\":[HumanMessage(content=f\"Hi my name is {name}\")],\"languages\":\"Telugu\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'హలో సూర్య విషాల్ గంటి, నమస్కారం! నేను మీకు సహాయం చేయడానికి ఇక్కడున్నాను. మీకు ఏం సహాయం అవసరం?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=f\"Hii I am {name}\")],\"languages\":\"Telugu\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'హాయ్ సూర్యా విషాల్, నమస్కారం! నేను మీకు తెలుగులో మాట్లాడడం ప్రారంభిస్తున్నాను. మీరు ఏం చెప్పాలనుకుంటున్నారు? నేను మీకు సహాయం చేయడానికి సిద్ధంగా ఉన్నాను. \\n\\nఅయితే, మీరు తమిళంలో మాట్లాడారు, కానీ నేను తెలుగులో మాట్లాడుతున్నాను. మీరు తెలుగులో మాట్లాడటం ఇష్టమైతే చక్కగా మాట్లాడుకోవచ్చు.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=f\"ஹாய், நான் சூர்யா விஷால்.\")],\"languages\":\"Telugu\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Manage the Conversation History</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "\n",
    "\n",
    "'trim_messages'helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surya/Desktop/Langchain/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I am Surya Vishal\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like Buttorscoth ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage (content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nuvvu Surya Vishal, na friend!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "#from langchain_core.messages import HumanMessage\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\"))\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"Nenu Evaru?\")],\n",
    "        \"languages\": \"Telugu\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you did a simple addition problem: 2 + 2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HumanMessage(content=\"whats 2 + 2\"),\n",
    "#    AIMessage(content=\"4\"),\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What math prolem I did?\")],\n",
    "        \"languages\": \"Tenglish\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the Message History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Surya Vishal.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is my name?\")],\n",
    "        \"languages\": \"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
